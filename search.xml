<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2019%2F05%2F14%2Fservice%2F</url>
    <content type="text"><![CDATA[title: 服务发现对比categories: 组件tags: 服务发现comments: true cap原理 Consistency(一致性)： 数据一致更新，所有数据变动都是同步的Availability(可用性)： 好的响应性能Partition tolerance(分区耐受性)： 可靠性 分区耐受性保证数据可持久存储，在各种情况下都不会出现数据丢失的问题。为了实现数据的持久性，不但需要在写入的时候保证数据能够持久存储，还需要能够将数据备份一个或多个副本，存放在不同的物理设备上，防止某个存储设备发生故障时，数据不会丢失。 数据一致性在数据有多份副本的情况下，如果网络、服务器、软件出现了故障，会导致部分副本写入失败。这就造成了多个副本之间的数据不一致，数据内容冲突。 数据可用性多个副本分别存储于不同的物理设备的情况下，如果某个设备损坏，就需要从另一个数据存储设备上访问数据。如果这个过程不能很快完成，或者在完成的过程中需要停止终端用户访问数据，那么在切换存储设备的这段时间内，数据就是不可访问的。 常用服务发现特性对比 feature consul zookeeper etcd eureka 服务健康检查 服务状态、内存,硬盘等 (弱)长链接,keepalive 连接心跳 可配支持 多数据中心 支持 - - - kv存储服务 支持 支持 支持 - 一致性 raft paxos raft - cap原理 CA CP CP AP 使用接口 http和dns 客户端 http/grpc http watch支持 全量/支持long polling 支持 支持long polling 支持long polling/大部分增量 自身监控 metrics - metrics metrics 安全 acl/https acl http支持(弱) -]]></content>
  </entry>
  <entry>
    <title><![CDATA[gorutine和线程区别]]></title>
    <url>%2F2019%2F04%2F15%2Fgorutine%2F</url>
    <content type="text"><![CDATA[goroutine 比线程更轻量级，可以创建十万、百万不用担心资源问题。 goroutine 和 chan 搭配使用，实现多线程、高并发 实现起来要方便很多。 线程的栈内存大小一般是固定的2M gorutine的栈内存可变 初始大小2kb 随着需求可以扩大到1gb 从调度上讲，线程的调度由 OS 的内核完成；线程的切换需要CPU寄存器和内存的数据交换，从而切换不同的线程上下文。 其触发方式为 CPU时钟。而goroutine 的调度 则比较轻量级，由go自身的调度器完成；其只关心当前go程序内协程的调度；触发方式为 go内部的事件，time.sleep,通道阻塞，互斥量操作等]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>gorutine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[kafka消息中间件]]></title>
    <url>%2F2018%2F12%2F19%2Fkafka%2F</url>
    <content type="text"><![CDATA[cli of kafka start zookeeper 1zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties start kafka 1kafka-server-start /usr/local/etc/kafka/server.properties create topic 12cd /usr/local/Cellar/kafka/2.1.0./bin/kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test show topics 12cd /usr/local/Cellar/kafka/2.1.0./bin/kafka-topics --list --zookeeper localhost:2181 delete topic 12cd /usr/local/Cellar/kafka/2.1.0./bin/kafka-run-class kafka.admin.DeleteTopicCommand --topic test --zookeeper127.0.0.1:2181 start producer 12cd /usr/local/Cellar/kafka/2.1.0bin/kafka-console-producer --broker-list localhost:9092 --topic test start consumer 1234 cd /usr/local/Cellar/kafka/2.1.0 ./bin/kafka-console-consumer --bootstrap-server localhost:9092 --group cousunmer --topic test --from-beginning ``` - stop kafka cd /usr/local/Cellar/kafka/2.1.0 ./bin/kafka-server-stop 12- 查看消费组 - 查看消费组列表 ./bin/kafka-consumer-groups --bootstrap-server localhost:9092 --list 1- 查看某个消费组信息 /bin/kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group consumer03 12- 查看topic - 查看topic列表 ./bin/kafka-topics.sh --zookeeper localhost:2181 --list 1- 查看指定topic信息 ./bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic Hello-Kafka 1- 修改topic分区数 ./bin/kafka-topics.sh --zookeeper localhost：2181 --alter --topic Hello-Kafka --partitions 3 ``` why need kafka? 解藕消息的生产和消费 缓冲 并行 设计目标 消息持久化：以时间复杂度为O(1)的方式提供消息持久化能力，即使对TB级以上的数据也能保证常数时间复杂度的访问性能。 高吞吐：在廉价的商用机器上也能支持单机每秒10万条以上的吞吐量。 分布式：支持消息分区以及分布式消费，并保证分区内的消息顺序。 跨平台：支持不同语言平台的客户端。 实时性：支持实时数据处理和离线数据处理。 伸缩性：支持水平扩展（producer可以将数据发给多个broker上的多个partition,consumer也可以从多个broker上的不同partition读取数据） 使用场景1: 解藕 各个系统之间通过消息系统这个统一的接口交换数据，无须关心彼此的存在 冗余 消息系统具有持久化的能力，规避消息处理前丢失的风险 拓展 消息系统是统一的数据接口 各系统可独立扩展 异步通信 在不需要立即处理请求的情况下 可以将请求放入消息系统 合适的时候再处理 峰值处理能力 消息系统可以顶住峰值流量 业务系统可根据处理能力从消息系统获取并处理对应量的请求 可恢复性 系统中部分组件失效不影响整个系统 恢复后仍可从消息系统获取并处理数据 常用消息系统对比 RabbitMQ erlang编写 支持多协议AMQP，XMPP,SMTP,STOMP,支持负载均衡 数据持久化 支持peer-2-peer和发布/订阅模式 Redis 轻量级。就入队操作而言 redis对于短消息小于10kb的性能比rabbitmq好 ZeroMQ 轻量级 不需要单独消息服务器或者中间件，应用程序扮演该角色，peer-2-peer本质是一个库 ActiveMQ JMS实现 peer-to-peer 支持持久化 XA分布式事务 kafka高性能跨语言的分布式发布/订阅消息系统 数据持久化 全分布式 同时支持在线和离线处理 MetaQ/RocketMQ 纯java实现 发布/订阅消息系统 支持本地事务和分布式事务 zookeeper &amp; kafkakafka使用zookeeper来实现动态的集群扩展，不需要更改客户端（producer和consumer）的配置。broker会在zookeeper注册并保持相关的元数据（topic，partition信息等）更新。而客户端会在zookeeper上注册相关的watcher。一旦zookeeper发生变化，客户端能及时感知并作出相应调整。 说明：Producer端使用zookeeper用来”发现”broker列表,以及和Topic下每个partition的leader建立socket连接并发送消息。也就是说每个Topic的partition是由Lead角色的Broker端使用zookeeper来注册broker信息,以及监测partition leader存活性.Consumer端使用zookeeper用来注册consumer信息,其中包括consumer消费的partition列表等,同时也用来发现broker列表,并和partition leader建立socket连接,并获取消息. 消息传递pull &amp; push Producer和consumer采用的是push-and-pull模式 Producer只管向broker push消息，consumer只管从broker pull消息，两者对消息的生产和消费是异步的 question: customer应该从brokes拉取消息还是brokers将消息推送到consumer，也就是pull还push? push 优势： 延时低 劣势： push模式很难适应消费速率不同的消费者，因为消息发送速率是由broker决定的。当broker推送速率远高于消费者消费速率，consumer可能崩溃。push模式的目标是尽可能以最快速度传递消息，但是这样很容易造成consumer来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。 pull(kafka选择的模式) 优势: 而pull模式则可以根据consumer的消费能力以适当的速率消费消息。 劣势: 如果处理不好，实时性不足(kafka使用long polling) 如果broker没有可供消费的消息，将导致consumer不断在循环中轮询，直到新消息到t达。为了避免这点，Kafka有个参数可以让consumer阻塞知道新消息到达(也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发送） Semantic topic &amp; partition 一个队列只有一种topic,一种topic的消息可以根据key值分散到多条队列中。 topic在逻辑上可以被认为是一个在的queue，每条消费都必须指定它的topic，可以简单理解为必须指明把这条消息放进哪个queue里。为了使得Kafka的吞吐率可以水平扩展，物理上把topic分成一个或多个partition（为了加快消费速度），每个partition在物理上对应一个文件夹，该文件夹下存储这个partition的所有消息和索引文件 broker 消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。 offset 每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset,用于partition唯一标识一条消息 kafka 支持多个consumer group 消费一条消息。但是如果一个consumer group 下有多个consumer，那么只能有一个consumer消费该条消息。这种机制可实现消息的单播和广播（可通过启动多个consumer验证）。 publish &amp; subscribe 生产者(producer)生产消息(数据流), 将消息发送到到kafka指定的主题队列(topic)中，也可以发送到topic中的指定分区(partition)中，消费者(consumer)从kafka的指定队列中获取消息，然后来处理消息 相同的消费者组中不能有比分区更多的消费者，否则多出的消费者一直处于空等待，不会收到消息 delivery guarantee： At most once 消息可能会丢，但绝不会重复传输读完消息先commit再处理，如果消息在commit后还没来得及处理就crash了，下次重新开始工作后无法读到刚刚提交但未处理的消息。 At least one 消息绝不会丢，但可能会重复传输先处理完再commit,如果消息在处理完但在commit之前crash了，下次重新开始工作后还会处理未commit的消息 Exactly once 每条消息肯定会被传输一次且仅传输一次，很多时候这是用户所想要的 代码地址：https://github.com/lanshipeng/kafka-example]]></content>
      <categories>
        <category>消息队列</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[xargs]]></title>
    <url>%2F2018%2F12%2F18%2Fxargs%2F</url>
    <content type="text"><![CDATA[xargs 命令可以通过管道接受字符串，并将接收到的字符串通过空格分割成许多参数(默认情况下是通过空格分割) 然后将参数传递给其后面的命令，作为后面命令的命令行参数 -dxargs将其标准输入中的内容以空白(包括空格、Tab、回车换行等)分割成多个后当作命令行参数传给后面的命令 1echo &quot;11@22@33&quot; |xargs -d &apos;@&apos; echo]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>xargs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[curl参数]]></title>
    <url>%2F2018%2F12%2F18%2Fcurl%2F</url>
    <content type="text"><![CDATA[curl常用参数 -o 输出到文件1curl -o home.html http://www.baidu.com -s 不输出任何东西1curl -s -# 进度条显示当前传送状态-O 后面的url要具体到某个文件，不然抓不下来1curl -# -O http://www.baidu.com/1.jpg -x 使用http代理1curl -x 24.10.28.84:32779 -o home.html http://www.baidu.com 断点续传，-C(大写的)1curl -C -O http://www.baidu.com/1.jpg 使用cookie1curl -b ./cookie.txt http://www.baidu.com/admin 模拟表单信息，模拟登录，保存cookie信息1curl -c ./cookie_c.txt -F log=aaaa -F pwd=****** http://blog.51yip.com/wp-login.php 模拟表单信息，模拟登录，保存头信息1curl -D ./cookie_c.txt -F log=aaaa -F pwd=****** http://blog.51yip.com/wp-login.php]]></content>
      <categories>
        <category>协议</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[md转html]]></title>
    <url>%2F2018%2F12%2F18%2Fpandoc%2F</url>
    <content type="text"><![CDATA[md 转html 1pandoc -s -S --toc -c github2.css a.md -o a.html math.tex 转html math.tex文件 123456789% Pandoc math demos$a^2 + b^2 = c^2$$v(t) = v_0 + \frac&#123;1&#125;&#123;2&#125;at^2$$\gamma = \frac&#123;1&#125;&#123;\sqrt&#123;1 - v^2/c^2&#125;&#125;$$\exists x \forall y (Rxy \equiv Ryx)$$p \wedge q \models p$$\Box\diamond p\equiv\diamond p$$\int_&#123;0&#125;^&#123;1&#125; x dx = \left[ \frac&#123;1&#125;&#123;2&#125;x^2 \right]_&#123;0&#125;^&#123;1&#125; = \frac&#123;1&#125;&#123;2&#125;$$e^x = \sum_&#123;n=0&#125;^\infty \frac&#123;x^n&#125;&#123;n!&#125; = \lim_&#123;n\rightarrow\infty&#125; (1+x/n)^n$ 1pandoc math.tex -s --mathml -o mathMathML.html 命令行参数 -s –standalone转换输出文档时会自动加上合适的header和footer(例如standalone HTML, LaTeX, RTF) -S –toc –data-dir=DIRECTORY指定用户数据目录，设定之后会在该目录下搜索pandoc数据文件。如果没有指定该选项，则会使用默认的用户数据目录:$HOME/.pandoc可通过pandoc –version命令查看 -c URL, –css=URL链接到CSS样式表。该选项能够使用多次来引入多个文件，所指定的文件能够以指定的顺序依次引入 -mathml 参数强制 Pandoc 将 LaTeX 中的数学公式转换成 MathML]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>pandoc</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2018%2F12%2F18%2Fjq%2F</url>
    <content type="text"><![CDATA[title: jqcategories: json文本处理 jqjq可以对json数据进行分片、过滤、映射和转换，和sed、awk、grep等命令一样，都可以让你轻松地把玩文本 “.”最简单的jq程序是表达式&quot;.&quot; 1cat json.text|jq . example 123456789101112131415161718&#123;&quot;name&quot;: &quot;tool&quot;,&quot;url&quot;: &quot;http://tool.china.com&quot;,&quot;addr&quot;: &#123; &quot;city&quot;: &quot;beijing&quot;, &quot;country&quot;: &quot;china&quot;&#125;,&quot;array&quot;: [ &#123; &quot;comp&quot;: &quot;google&quot;, &quot;url&quot;: &quot;http://www.google.com&quot; &#125;, &#123; &quot;comp&quot;: &quot;baidu&quot;, &quot;url&quot;: &quot;http://www.baidu.com&quot; &#125;]&#125; index1cat json.text|jq &apos;.[0]&apos; 管道 |1cat json.txt | jq &apos;.[0] | &#123;name:.name,city:.addr.city&#125;&apos; echo: { &quot;name&quot;:&quot;jjj&quot;, &quot;city&quot;:&quot;bj&quot; } 1cat json.txt | jq &apos;.[0] | &#123;name:.array[0].comp,city:.addr.city&#125;&apos; echo: { &quot;name&quot;:&quot;google&quot;, &quot;city&quot;:&quot;bj&quot; } [] 把jq的输出当作一个数组{} 自定义key1cat json.txt | jq &apos;.[0] | &#123;username:.array[0].comp,livecity:.addr.city&#125;&apos;]]></content>
  </entry>
  <entry>
    <title><![CDATA[atomic原子操作]]></title>
    <url>%2F2018%2F12%2F10%2Fatomic%2F</url>
    <content type="text"><![CDATA[go的原子操作 atomic 提供的原子操作能够确保任一时刻只有一个goroutine对变量进行操作，善用 atomic 能够避免程序中出现大量的锁操作。 atomic常见操作有： 增减 第一个参数必须是指针类型的值，通过指针变量可以获取被操作数在内存中的地址，从而施加特殊的CPU指令，确保同一时间只有一个goroutine能够进行操作。 func AddInt32(addr *int32, delta int32) (new int32) func AddInt64(addr *int64, delta int64) (new int64) func AddUint32(addr *uint32, delta uint32) (new uint32) func AddUint64(addr *uint64, delta uint64) (new uint64) func AddUintptr(addr *uintptr, delta uintptr) (new uintptr) 12var m int64=0atomic.AddInt32(&amp;m,3) 载入 载入操作能够保证原子的读变量的值，当读取的时候，任何其他CPU操作都无法对该变量进行读写，其实现机制受到底层硬件的支持。 func LoadInt32(addr *int32) (val int32) func LoadInt64(addr *int64) (val int64) func LoadPointer(addr *unsafe.Pointer) (val unsafe.Pointer) func LoadUint32(addr *uint32) (val uint32) func LoadUint64(addr *uint64) (val uint64) func LoadUintptr(addr *uintptr) (val uintptr) 交换 相对于CAS，明显此类操作更为暴力直接，并不管变量的旧值是否被改变，直接赋予新值然后返回背替换的值。 unc SwapInt32(addr *int32, new int32) (old int32) func SwapInt64(addr *int64, new int64) (old int64) func SwapPointer(addr *unsafe.Pointer, new unsafe.Pointer) (old unsafe.Pointer) func SwapUint32(addr *uint32, new uint32) (old uint32) func SwapUint64(addr *uint64, new uint64) (old uint64) func SwapUintptr(addr *uintptr, new uintptr) (old uintptr) 比较并交换 该操作在进行交换前首先确保变量的值未被更改，即仍然保持参数 old 所记录的值，满足此前提下才进行交换操作。CAS的做法类似操作数据库时常见的乐观锁机制。 需要注意的是，当有大量的goroutine 对变量进行读写操作时，可能导致CAS操作无法成功，这时可以利用for循环多次尝试。 123456789var value int64func atomicAddOp(tmp int64) &#123; for &#123; oldValue := value if atomic.CompareAndSwapInt64(&amp;value, oldValue, oldValue+tmp) &#123; return &#125; &#125;&#125; func CompareAndSwapInt32(addr *int32, old, new int32) (swapped bool) func CompareAndSwapInt64(addr *int64, old, new int64) (swapped bool) func CompareAndSwapPointer(addr *unsafe.Pointer, old, new unsafe.Pointer) (swapped bool) func CompareAndSwapUint32(addr *uint32, old, new uint32) (swapped bool) func CompareAndSwapUint64(addr *uint64, old, new uint64) (swapped bool) func CompareAndSwapUintptr(addr *uintptr, old, new uintptr) (swapped bool) 存储 此类操作确保了写变量的原子性，避免其他操作读到了修改变量过程中的脏数据。 func StoreInt32(addr *int32, val int32) func StoreInt64(addr *int64, val int64) func StorePointer(addr *unsafe.Pointer, val unsafe.Pointer) func StoreUint32(addr *uint32, val uint32) func StoreUint64(addr *uint64, val uint64) func StoreUintptr(addr *uintptr, val uintptr)]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>atomic</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[memcached's note]]></title>
    <url>%2F2018%2F11%2F11%2Fmemcached%2F</url>
    <content type="text"><![CDATA[save cmd set key flags exptime bytes [noreply]value 说明： （如果set的key已经存在，该命令可以更新该key所对应的原来的数据，也就是实现更新的作用。 [key]: key-value 中的key 用于查找缓存值 [flags]: 包括简直对的整型参数，客户机使用它存储关于简直对的额外信息 [exptime]: 在缓存中保存键值对的时间长度 （以s为单位） [bytes]: 缓存中字节数 [noreply]: 告知服务器不需要返回数据 [value]: 存储的值(始终位于第二行) 1234567set runoob 0 900 9memcachedSTOREDget runoobVALUE runoob 0 9memcachedEND out info: – STORED：保存成功后输出。 – ERROR：在保存失败后输出。 add key flags exptime bytes [noreply]value 说明： （如果 add 的 key 已经存在，则不会更新数据(过期的 key 会更新)，之前的值将仍然保持相同，并且您将获得响应 NOT_STORED） 1234567add new_key 0 900 10data_valueSTOREDget new_keyVALUE new_key 0 10data_valueEND out info; – STORED：保存成功后输出。 – NOT_STORED ：在保存失败后输出。 replace key flags exptime bytes [noreply]value 说明： （如果 key 不存在，则替换失败，并且您将获得响应 NOT_STORED。） 12345678910111213add mykey 0 900 10data_valueSTOREDget mykeyVALUE mykey 0 10data_valueENDreplace mykey 0 900 16some_other_valueget mykeyVALUE mykey 0 16some_other_valueEND out info: – STORED：保存成功后输出。 – NOT_STORED：执行替换失败后输出。 append key flags exptime bytes [noreply]value 说明： （Memcached append 命令用于向已存在 key(键) 的 value(数据值) 后面追加数据 。） 1234567891011121314set runoob 0 900 9memcachedSTOREDget runoobVALUE runoob 0 9memcachedENDappend runoob 0 900 5redisSTOREDget runoobVALUE runoob 0 14memcachedredisEND out info: – STORED：保存成功后输出。 – NOT_STORED：该键在 Memcached 上不存在。 – CLIENT_ERROR：执行错误。 prepend key flags exptime bytes [noreply]value 说明： （ Memcached prepend 命令用于向已存在 key(键) 的 value(数据值) 前面追加数据 。） 1234567891011121314set runoob 0 900 9memcachedSTOREDget runoobVALUE runoob 0 9memcachedENDprepend runoob 0 900 5redisSTOREDget runoobVALUE runoob 0 14redismemcachedEND out info: – STORED：保存成功后输出。 – NOT_STORED：该键在 Memcached 上不存在。 – CLIENT_ERROR：执行错误。 cas key flags exptime bytes unique_cas_token [noreply] value params: unique_cas_token通过 gets 命令获取的一个唯一的64位值。 out info: -- STORED：保存成功后输出。 -- ERROR：保存出错或语法错误。 -- EXISTS：在最后一次取值后另外一个用户也在更新该数据。 -- NOT_FOUND：Memcached 服务上不存在该键值。 get key 说明： （ Memcached get 命令获取存储在 key(键) 中的 value(数据值) ，如果 key 不存在，则返回空。） 多个key使用空格隔开： get key1 key2 key3 gets key 说明： (Memcached gets 命令获取带有 CAS 令牌存 的 value(数据值) ，如果 key 不存在，则返回空。) 1234567set runoob 0 900 9memcachedSTOREDgets runoobVALUE runoob 0 9 1memcachedEND 使用 gets 命令的输出结果中，在最后一列的数字 1 代表了 key 为 runoob 的 CAS 令牌 delete key [noreply] 说明： (删除已存在的key) 12345678910111213set runoob 0 900 9memcachedSTOREDget runoobVALUE runoob 0 9memcachedENDdelete runoobDELETEDget runoobENDdelete runoobNOT_FOUND out info: – DELETED：删除成功。 – ERROR：语法错误或删除失败。 – NOT_FOUND：key 不存在。 incr key increment_value 说明：key：键值 key-value 结构中的 key，用于查找缓存值。increment_value： 增加的数值。 12345678910111213set visitors 0 900 210STOREDget visitorsVALUE visitors 0 210ENDincr visitors 515get visitorsVALUE visitors 0 215END 12345678910111213set visitors 0 900 210STOREDget visitorsVALUE visitors 0 210ENDdecr visitors 55get visitorsVALUE visitors 0 15END out info:– NOT_FOUND：key 不存在。– CLIENT_ERROR：自增值不是对象。– ERROR其他错误，如语法错误等。 count cmd stats Memcached stats 命令用于返回统计信息例如 PID(进程号)、版本号、连接数等。 stats items Memcached stats items 命令用于显示各个 slab 中 item 的数目和存储时长(最后一次访问距离现在的秒数)。 stats sizes Memcached stats sizes 命令用于显示所有item的大小和个数。 该信息返回两列，第一列是 item 的大小，第二列是 item 的个数。 stats slabs Memcached stats slabs 命令用于显示各个slab的信息，包括chunk的大小、数目、使用情况等。 flush_all Memcached flush_all 命令用于清理缓存中的所有 key=&gt;value(键=&gt;值) 对。该命令提供了一个可选参数 time，用于在制定的时间后执行清理缓存操作。]]></content>
      <categories>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql数据库使用规范总结]]></title>
    <url>%2F2018%2F10%2F26%2Fsql%2F</url>
    <content type="text"><![CDATA[基本规范 表存储引擎设置为innodb 表字符集默认使用utf8,必要时使用utf8mb4。utf8mb4是utf8的超集,有存储4字节例如表情符号时使用他。 禁止数据库中存储大文件,例如照片.可以将大文件存储在对象存储系统中。数据库存储路径 一般不使用存储过程、视图、触发器,event.对数据库性能影响大，调试，排错，迁移都比较困难.拓展性差 对于互联网业务，能让站点层和服务层干的事,不要交到数据库 命名规范 库名，表名,列名都必须小写,采用下划线分割 库名，表名,列名最好见名知意。长度不超过32个字符 库备份以bak为前缀，日期为后缀 从库以-s为后缀 备库以-ss为后缀 建表规范 单实例表个数控制在2000个以内 单表分表个数控制在1024个以内 表必须有主键，一般使用unsigned整数类型为主键 删除无主键的表,如果是row模式的主从架构。从库会挂住 一般不使用外键,如果要保证完整性。应该由应用程式实现 外键使得表之间相互耦合，影响update/delete性能.有可能造成死锁 建议将大字段,访问频率少的字段拆分到单独表中存储，分离冷热数据 列设计规范 根据业务区分使用tinyint/int/bigint,分别占用1/4/8字节 根据业务区分使用char/varchar 字段长度固定,或者长度近似的业务场景,适用char,能减少碎片,查询性能高 字段长度相差大，或者更新少的业务场景，适合使用varchar,可以减少空间 根据业务区分使用datetime/timestamp(分别占5/4字节) 把not null字段设置为默认值.因为null的列使用索引统计,值都更加复杂。更难优化。只能使用is null 或者is not null 而在=/!=/in/not in有大坑 使用int unsigned 存储ipv4 ,不要用char(15). 使用varchar(20)存储手机号,不要用整数 varchar可以模糊查询 索引规范 唯一索引使用uniq_[字段名]来命名 非唯一索引使用idx_[字段名]来命名 单张表索引数量控制在5个以内 太多索引影响写性能;生成执行计划时,如果索引太多,会降低性能.并可能导致mysql选择不到最优索引 组合索引字段数建议不超过5个 不建议在频繁更新的字段上建立索引 非必要不用join查询，如果要join查询,被join的字段必须类型相同,并建立索引 组合索引最前缀原则,避免重复建索引,如果建立了(a,b,c)相当于建立了(a),(a,b),(a,b,c) sql书写规范 尽量不写select *，只获取必要字段.否则会增加cpu/io/内存/带宽的消耗 同一个字段上的or改写成in,in的值要少于50个 应用程序捕获sql异常，方便定位线上问题 insert必须指定字段,禁止使用insert into table values() 尽量不对大表join和子查询 建表实例1234567891011121314CREATE TABLE `user` (`user_id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT &apos;会员信息表主键，自增长&apos;,`uuid` bigint(20) DEFAULT &apos;0&apos; COMMENT &apos;会员唯一标识表主键，自增长&apos;,`guid` bigint(20) DEFAULT &apos;0&apos; COMMENT &apos;用户中心全局ID&apos;,`is_certed` tinyint(4) DEFAULT &apos;2&apos; COMMENT &apos;是否认证，1 认证 2 未认证&apos;,`mobile` varchar(40) COLLATE utf8mb4_bin NOT NULL COMMENT &apos;手机号码&apos;,`last_login_tm` datetime(6) DEFAULT &apos;0000-00-00 00:00:00.000000&apos; COMMENT &apos;最后一次登录时间&apos;,`last_login_device` varchar(20) COLLATE utf8mb4_bin DEFAULT NULL COMMENT &apos;最后一次登录设备号&apos;,`remark` varchar(250) COLLATE utf8mb4_bin DEFAULT &apos;&apos; COMMENT &apos;备注&apos;,`is_deleted` tinyint(4) DEFAULT &apos;1&apos; COMMENT &apos;是否删除，1 未删除，2 已删除&apos;,`created_tm` datetime(6) DEFAULT CURRENT_TIMESTAMP(6) COMMENT &apos;创建时间，默认是 CURRENT_TIMESTAMP(6)&apos;,`updated_tm` datetime(6) DEFAULT &apos;0000-00-00 00:00:00.000000&apos; ON UPDATE CURRENT_TIMESTAMP(6) COMMENT &apos;修改时间，修改时 CURRENT_TIMESTAMP(6)&apos;,PRIMARY KEY (`user_id`)) ENGINE=InnoDB AUTO_INCREMENT=0 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_bin COMMENT=&apos;会员信息表&apos;;]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>数据库规范</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序]]></title>
    <url>%2F2018%2F10%2F25%2Fsort%2F</url>
    <content type="text"><![CDATA[golang 实现归并和堆排序 1.归并排序 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package mainimport &quot;fmt&quot;func main()&#123; a := make([]int,0,0) r := make([]int,0,0) a = []int&#123;4,1,3,2,6,5,7&#125; r = []int&#123;0,0,0,0,0,0,0&#125; mergesort(a,0,6,r) fmt.Println(a) fmt.Println(r)&#125;func Swap(a *int,b *int)&#123; temp := *a *a = *b *b = temp&#125;func mergesort(a []int,start,end int64,result []int)&#123; if end - start == 0&#123; return &#125; if end - start == 1&#123; if a[start] &gt; a[end]&#123; Swap(&amp;a[start],&amp;a[end]) &#125; &#125;else&#123; mergesort(a,start,(end-start+1)/2 + start,result) mergesort(a,(end-start+1)/2 +1 + start,end,result) merge(a,start,end,result) var i int64 =0 for i=start;i&lt;=end;i++&#123; a[i] = result[i] &#125; &#125;&#125;func merge(a []int,start,end int64,result []int)&#123; left_index := start left_length := (end-start+1)/2 +1 right_index := start + left_length result_index := start for left_index &lt; start + left_length &amp;&amp; right_index &lt; end+1 &#123; if a[left_index] &lt;= a[right_index]&#123; result[result_index] = a[left_index] result_index++ left_index++ &#125;else&#123; result[result_index] = a[right_index] right_index++ result_index++ &#125; &#125; for left_index &lt; start +left_length&#123; result[result_index] = a[left_index] result_index++ left_index++ &#125; for right_index &lt; end+1&#123; result[result_index] = a[right_index] right_index++ result_index++ &#125;&#125; 2.堆排序 123456789101112131415161718192021222324252627282930313233343536373839404142434445package mainimport &quot;fmt&quot;func main()&#123; a := make([]int,0,0) a = []int&#123;1,4,2,3,7,9,8&#125; heapsort(a) fmt.Println(a)&#125;func swap(a *int,b *int)&#123; temp := *a *a = *b *b = temp&#125;func heapsort(a []int)&#123; //创建大顶堆 var i int = 0 var j int = 0 for i= len(a)/2;i&gt;=0;i--&#123; heapadjust(a,i,len(a)) &#125; for j= len(a) -1 ;j&gt;=1;j--&#123; swap(&amp;a[0],&amp;a[j]) heapadjust(a,0,j) &#125;&#125;func heapadjust(a []int,i,length int)&#123; var left int = 2*i +1 if left &lt; length&#123; maxIndex := left right := left + 1 if a[right] &gt; a[left] &amp;&amp; right &lt; length&#123; maxIndex = right &#125; if a[maxIndex] &gt; a[i]&#123; swap(&amp;a[maxIndex],&amp;a[i]) heapadjust(a,maxIndex,length) &#125; &#125;&#125;]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>堆排序</tag>
        <tag>归并排序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单链表]]></title>
    <url>%2F2018%2F10%2F25%2Flist%2F</url>
    <content type="text"><![CDATA[单链表的创建、插入、删除 倒置 go 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091type ListNode struct&#123; value int next *ListNode&#125;//创建单链表func (this *ListNode)CreateList()*ListNode&#123; head := new(ListNode) ptail := new(ListNode) ptail = head for i :=0; i &lt;= 10; i++&#123; xNode := new(ListNode) xNode.value = i xNode.next = nil ptail.next = xNode ptail = xNode &#125; head = head.next ptail.next = nil return head&#125;//删除节点func (this *ListNode)DeleteListNode(head* ListNode,val int)&#123; if head == nil&#123; return nil &#125; temp := new(ListNode) p := new(ListNode) p = head for p.next != nil &amp;&amp; p.value != val&#123; temp = p p = p.next &#125; if p.value == val&#123; if p == head&#123; head = temp.next &#125;else&#123; temp.next = p.next &#125; &#125; return head&#125;//插入节点func (this *ListNode)InsertNode(head* ListNode,val int)*ListNode&#123; if head == nil&#123; return &#125; xNode := new(ListNode) xNode.value = val xNode.next = nil temp := new(ListNode) p := new(ListNode) p = head for p.next != nil &amp;&amp; p.value &lt; val&#123; temp = p p = p.next &#125; if p.value &lt;= val&#123; if p == head&#123; head = xNode xNode.next = p &#125;else&#123; temp.next = xNode xNode.next = p &#125; &#125;else&#123; p.next = xNode xNode.next = nil &#125; return head&#125;//链表倒置func (this *ListNode)Reverse(head* ListNode)*ListNode&#123; if head==nil&#123; return nil &#125; temp := new(ListNode) p := new(ListNode) p = head.next head.next=nil for p != nil&#123; temp = p.next p.next = head head = p p = temp &#125; return head&#125; c++ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134struct ListNode&#123; ListNode *next; int val;&#125;class Solution&#123;public: ListNode* CreateListNode()&#123; ListNode* head =new ListNode; p = head; for (int i =0; i &lt;10; i++)&#123; ListNode* node =new ListNode; node -&gt; next =NULL; node -&gt; val = i; p-&gt;next = node; p = node; &#125; head = head-&gt;next; p-&gt;next = NULL; return head; &#125; ListNode* DeletedListNode(ListNode* head,int val)&#123; if head == NULL&#123; return NULL; &#125; ListNode* temp = NULL; ListNode* p = head; while(p-&gt;next != NULL &amp;&amp; p-&gt;val != val)&#123; temp = p; p = p-&gt;next; &#125; if (p-&gt;val == val)&#123; if (p == head)&#123; head = p-&gt;next; delete p; &#125; else&#123; temp-&gt;next = p-&gt;next; delete p; &#125; &#125; return head; &#125; ListNode* InsertListNode(ListNode* head,int val)&#123; ListNode* p = head; ListNode* temp = NULL; ListNode* node = new ListNode; node-&gt;val = val; while(p-&gt;next != NULL &amp;&amp; p-&gt;val &lt; node-&gt;val)&#123; temp = p; p= p-&gt;next; &#125; if (node-&gt;val &lt;= p-&gt;val)&#123; if (p == head)&#123;//头部插入 head = node; node -&gt; next = p; &#125;else&#123;//中间插入 temp -&gt; next = node; node -&gt; next = p; &#125; &#125;else&#123;//链表尾部插入 p-&gt;next = node; node-&gt;next = NULL; &#125; return head; &#125; ListNode* ReverseListNode(ListNode* head)&#123; if (head == NULL)&#123; return NULL; &#125; ListNode* temp = NULL; ListNode* p = head; head-&gt;next = NULL; while(p!=NULL)&#123; temp = p-&gt;next; p-&gt;next = head; head = p; p = temp; &#125; return head; &#125; ListNode* DeleteListNode(ListNode* head,int val)&#123; if (head == NULL) return NULL; ListNode* temp = NULL; ListNode* p = head; while(val &lt; p-&gt;val &amp;&amp; p-&gt;next !=NULL)&#123; temp = p; p = p-&gt;next; &#125; if (p-&gt;val == val)&#123; if (p == head)&#123; head = p-&gt;next; delete p; &#125;else&#123; temp-&gt;next = p-&gt;next; delete p; &#125; &#125; return head; &#125; ListNode* InsertListNode(ListNode* head,int val)&#123; ListNode* temp = NULL; ListNode* p = head; ListNode* newNode = new ListNode; newNode-&gt;val = val; while(val &lt; p-&gt;val &amp;&amp; p-&gt;next !=NULL)&#123; temp = p; p = p-&gt;next; &#125; if (p-&gt;val &lt;= newNode-&gt;val )&#123; if(p == head)&#123; head = newNode; newNode-&gt;next = p; &#125;else&#123; temp-&gt;next = newNode; newNode-&gt;next = p; &#125; &#125;else&#123;//尾部插入 p-&gt;next = newNode; newNode-&gt;next = NULL; &#125; &#125;&#125;]]></content>
      <categories>
        <category>数据结构</category>
      </categories>
      <tags>
        <tag>链表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http相关特性]]></title>
    <url>%2F2018%2F10%2F25%2Fhttp%2F</url>
    <content type="text"><![CDATA[http通信的过程(1) 建立tcp链接(2) web浏览器向web服务器发送请求命令(3) web浏览器发送请求头消息(4) web服务器应答(5) web服务器发送应答头消息(6) web服务器向浏览器发送数据(7) web服务器关闭tcp链接 HTTP2.0和HTTP1.X相比的新特性1.新的二进制格式（Binary Format），HTTP1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。 2.多路复用（MultiPlexing），即连接共享，即每一个request都是是用作连接共享机制的。一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的 id将request再归属到各自不同的服务端请求里面。 3.header压缩，如上文中所言，对前面提到过HTTP1.x的header带有大量信息，而且每次都要重复发送，HTTP2.0使用encoder来减少需要传输的header大小，通讯双方各自cache一份header fields表，既避免了重复header的传输，又减小了需要传输的大小。 4.服务端推送（server push），同SPDY一样，HTTP2.0也具有server push功能。 http url 字符含义 URL特殊符号及对应的十六进制值编码： (1)’+’ URL中+号表示空格 %2B (2)空格 URL中的空格可以用+号或者编码 %20 (3)/ 分隔目录和子目录 %2F (4)? 分隔实际的 URL 和参数 %3F (5)% 指定特殊字符 %25 (6)’#’ 表示书签 %23 (7)&amp; URL中指定的参数间的分隔符 %26 (8)= URL中指定参数的值 %3D]]></content>
      <categories>
        <category>协议</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[my first blog]]></title>
    <url>%2F2018%2F09%2F29%2Ffirst-blog%2F</url>
    <content type="text"><![CDATA[welcome to my first blog, to be continued 。。。。。。]]></content>
      <categories>
        <category>Hello</category>
      </categories>
  </entry>
</search>
